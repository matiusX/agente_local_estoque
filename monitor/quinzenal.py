import pandas as pd
import numpy as np
import os
import sys
import json
import glob
import re
from datetime import datetime
from dotenv import load_dotenv
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from typing import Dict, List, Any, Optional, Tuple
import logging
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from io import BytesIO
import base64

# Configura√ß√£o b√°sica
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class InventoryTrackingAgent:
    """
    Agente de acompanhamento quinzenal para monitorar a evolu√ß√£o das m√©tricas de estoque
    e avaliar o progresso das a√ß√µes implementadas.
    """
    
    def __init__(self, openai_api_key: str = None, model_name: str = "gpt-4o", temp=0.2):
        """
        Inicializa o agente de acompanhamento.
        
        Args:
            openai_api_key: Chave da API OpenAI (padr√£o para vari√°vel de ambiente)
            model_name: Nome do modelo OpenAI a ser usado
            temp: Temperatura para o modelo LLM
        """
        self.api_key = openai_api_key or os.environ.get("OPENAI_API_KEY")
        self.model_name = model_name
        self.temp = temp
        self.llm = ChatOpenAI(
            temperature=temp, 
            model_name=self.model_name,
            openai_api_key=self.api_key
        )
        
        # Cria√ß√£o dos prompts e chains
        self.metrics_analysis_prompt = self._create_metrics_analysis_prompt()
        self.action_tracking_prompt = self._create_action_tracking_prompt()
        self.report_generation_prompt = self._create_report_generation_prompt()
        
        self.metrics_analysis_chain = LLMChain(llm=self.llm, prompt=self.metrics_analysis_prompt)
        self.action_tracking_chain = LLMChain(llm=self.llm, prompt=self.action_tracking_prompt)
        self.report_generation_chain = LLMChain(llm=self.llm, prompt=self.report_generation_prompt)
        
        # Armazenamento de dados processados
        self.metrics_history = {}
        self.baseline_metrics = {}
        self.current_metrics = {}
        self.action_plan = {}
        self.problem_analysis = {}
        self.cycle_count = 0
    
    def _create_metrics_analysis_prompt(self) -> PromptTemplate:
        """Cria o prompt para analisar a evolu√ß√£o das m√©tricas."""
        template = """
        Como especialista em gest√£o de estoque, analise a evolu√ß√£o das m√©tricas de estoque ao longo do tempo.
        
        ## M√©tricas Iniciais (Linha de Base)
        ```json
        {baseline_metrics}
        ```
        
        ## M√©tricas Atuais
        ```json
        {current_metrics}
        ```
        
        ## Hist√≥rico de M√©tricas
        ```json
        {metrics_history}
        ```
        
        ## Metas Estabelecidas
        ```json
        {target_metrics}
        ```
        
        ## Instru√ß√µes
        1. Compare as m√©tricas atuais com a linha de base e identifique as principais varia√ß√µes
        2. Avalie o progresso em rela√ß√£o √†s metas estabelecidas
        3. Identifique tend√™ncias (positivas ou negativas) nas m√©tricas-chave
        4. Destaque os desvios significativos do plano original
        5. Calcule a taxa de progresso para cada m√©trica-chave (porcentagem do caminho em dire√ß√£o √† meta)
        
        ## Formato de Sa√≠da
        Forne√ßa sua an√°lise como um objeto JSON com a seguinte estrutura:
        ```json
        {
          "metrics_comparison": [
            {
              "metric_name": "Nome da m√©trica",
              "baseline_value": valor_inicial,
              "current_value": valor_atual,
              "target_value": valor_meta,
              "absolute_change": mudan√ßa_absoluta,
              "percentage_change": "mudan√ßa_percentual%",
              "progress_rate": "taxa_de_progresso%",
              "trend": "increasing/decreasing/stable",
              "status": "on_track/at_risk/off_track",
              "insights": "An√°lise espec√≠fica desta m√©trica"
            }
          ],
          "overall_assessment": {
            "overall_progress": "taxa_global_de_progresso%",
            "on_track_metrics": n√∫mero_m√©tricas_no_caminho,
            "at_risk_metrics": n√∫mero_m√©tricas_em_risco,
            "off_track_metrics": n√∫mero_m√©tricas_fora_do_caminho,
            "key_achievements": ["conquista1", "conquista2"],
            "key_concerns": ["preocupa√ß√£o1", "preocupa√ß√£o2"]
          },
          "trends_identified": [
            {
              "trend_description": "Descri√ß√£o da tend√™ncia",
              "affected_metrics": ["m√©trica1", "m√©trica2"],
              "potential_impact": "Impacto potencial desta tend√™ncia",
              "recommendation": "Recomenda√ß√£o relacionada a esta tend√™ncia"
            }
          ]
        }
        ```
        
        Forne√ßa uma an√°lise profunda baseada em dados, com insights quantitativos e qualitativos.
        """
        
        return PromptTemplate(
            input_variables=["baseline_metrics", "current_metrics", "metrics_history", "target_metrics"],
            template=template
        )
    
    def _create_action_tracking_prompt(self) -> PromptTemplate:
        """Cria o prompt para acompanhar as a√ß√µes do plano original."""
        template = """
        Como especialista em gest√£o de estoque, avalie o progresso das a√ß√µes implementadas com base na evolu√ß√£o das m√©tricas.
        
        ## Plano de A√ß√£o Original
        ```markdown
        {action_plan}
        ```
        
        ## An√°lise de Problemas Original
        ```markdown
        {problem_analysis}
        ```
        
        ## Evolu√ß√£o das M√©tricas
        ```json
        {metrics_evolution}
        ```
        
        ## Instru√ß√µes
        1. Para cada a√ß√£o no plano original, avalie seu status atual com base na evolu√ß√£o das m√©tricas relacionadas
        2. Determine se cada a√ß√£o est√°: Completa, Em Andamento, Atrasada ou N√£o Iniciada
        3. Calcule o impacto financeiro observado para as a√ß√µes em andamento ou completas
        4. Identifique obst√°culos potenciais para a√ß√µes atrasadas ou n√£o iniciadas
        5. Sugira ajustes ou novas a√ß√µes com base nos resultados observados
        
        ## Formato de Sa√≠da
        Forne√ßa sua avalia√ß√£o como um objeto JSON com a seguinte estrutura:
        ```json
        {
          "action_status": [
            {
              "problem": "Descri√ß√£o do problema",
              "action": "Descri√ß√£o da a√ß√£o",
              "status": "complete/in_progress/delayed/not_started",
              "completion_percentage": percentual_de_conclus√£o,
              "related_metrics": ["m√©trica1", "m√©trica2"],
              "observed_impact": "Impacto observado at√© o momento",
              "financial_impact": "Estimativa do impacto financeiro observado",
              "obstacles": ["obst√°culo1", "obst√°culo2"],
              "recommended_adjustments": "Ajustes recomendados para esta a√ß√£o"
            }
          ],
          "overall_plan_status": {
            "actions_complete": n√∫mero_a√ß√µes_completas,
            "actions_in_progress": n√∫mero_a√ß√µes_em_andamento,
            "actions_delayed": n√∫mero_a√ß√µes_atrasadas,
            "actions_not_started": n√∫mero_a√ß√µes_n√£o_iniciadas,
            "overall_completion": "percentual_global_de_conclus√£o%",
            "financial_impact_to_date": "Impacto financeiro total observado at√© o momento"
          },
          "new_actions_recommended": [
            {
              "problem": "Problema relacionado",
              "action_description": "Descri√ß√£o da nova a√ß√£o recomendada",
              "rationale": "Justificativa para esta nova a√ß√£o",
              "expected_impact": "Impacto esperado desta a√ß√£o",
              "priority": "high/medium/low"
            }
          ]
        }
        ```
        
        Forne√ßa uma avalia√ß√£o objetiva baseada em evid√™ncias quantitativas das m√©tricas.
        """
        
        return PromptTemplate(
            input_variables=["action_plan", "problem_analysis", "metrics_evolution"],
            template=template
        )
    
    def _create_report_generation_prompt(self) -> PromptTemplate:
        """Cria o prompt para gerar o relat√≥rio quinzenal de acompanhamento."""
        template = """
        Como especialista em gest√£o de estoque, crie um relat√≥rio quinzenal detalhado de acompanhamento do plano de a√ß√£o.
        
        ## An√°lise de M√©tricas
        ```json
        {metrics_analysis}
        ```
        
        ## Status das A√ß√µes
        ```json
        {action_status}
        ```
        
        ## Ciclo de Acompanhamento
        Ciclo: {cycle_number}
        Data: {report_date}
        
        ## Instru√ß√µes
        Crie um relat√≥rio quinzenal completo que inclua:
        1. Resumo executivo do progresso geral
        2. Tabela de evolu√ß√£o das m√©tricas-chave (comparando linha base, meta e valor atual)
        3. Status atualizado de cada a√ß√£o do plano original
        4. Tend√™ncias identificadas e suas implica√ß√µes
        5. Recomenda√ß√µes para ajustes no plano
        6. Previs√£o para o pr√≥ximo per√≠odo
        
        ## Formato de Sa√≠da
        Forne√ßa o relat√≥rio em formato markdown estruturado e profissional.
        Utilize tabelas, listas e formata√ß√£o para facilitar a leitura.
        Inclua s√≠mbolos visuais para indicar status (üü¢ No caminho, üü° Em progresso, üü† Atrasado, üî¥ Cr√≠tico).
        
        O relat√≥rio deve ser detalhado, baseado em dados, mas tamb√©m acess√≠vel para gestores de neg√≥cios.
        Foque em insights acion√°veis e recomenda√ß√µes concretas.
        """
        
        return PromptTemplate(
            input_variables=["metrics_analysis", "action_status", "cycle_number", "report_date"],
            template=template
        )
    
    def load_data(self, 
                  scenario_pattern: str, 
                  action_plan_path: str, 
                  problem_analysis_path: str) -> None:
        """
        Carrega todos os dados necess√°rios para o acompanhamento.
        
        Args:
            scenario_pattern: Padr√£o para encontrar arquivos de cen√°rio (ex: "./cenarios/cenario1_*.json")
            action_plan_path: Caminho para o arquivo do plano de a√ß√£o
            problem_analysis_path: Caminho para o arquivo de an√°lise de problemas
        """
        logging.info(f"Carregando dados para an√°lise...")
        
        # Carrega cen√°rios de m√©tricas
        scenario_files = sorted(glob.glob(scenario_pattern))
        if not scenario_files:
            raise ValueError(f"Nenhum arquivo de cen√°rio encontrado com o padr√£o: {scenario_pattern}")
        
        # Extrai o n√∫mero de vers√£o do padr√£o de nome de arquivo
        def extract_version(filename):
            match = re.search(r'_(\d+)\.json$', filename)
            return int(match.group(1)) if match else 0
        
        # Ordena os arquivos por n√∫mero de vers√£o
        scenario_files.sort(key=extract_version)
        
        # Carrega todos os cen√°rios
        for file in scenario_files:
            version = extract_version(file)
            with open(file, "r") as f:
                metrics_data = json.load(f)
                self.metrics_history[version] = metrics_data
                
                # O primeiro cen√°rio √© a linha de base
                if version == 0:
                    self.baseline_metrics = metrics_data
                
                # O √∫ltimo cen√°rio √© o atual
                self.current_metrics = metrics_data
        
        # Carrega o plano de a√ß√£o
        try:
            with open(action_plan_path, "r") as f:
                self.action_plan = f.read()
        except Exception as e:
            raise ValueError(f"Erro ao carregar o plano de a√ß√£o: {e}")
        
        # Carrega a an√°lise de problemas
        try:
            with open(problem_analysis_path, "r") as f:
                self.problem_analysis = f.read()
        except Exception as e:
            raise ValueError(f"Erro ao carregar a an√°lise de problemas: {e}")
        
        # Extrai metas do plano de a√ß√£o
        self.target_metrics = self._extract_targets_from_action_plan()
        
        logging.info(f"Dados carregados com sucesso: {len(self.metrics_history)} cen√°rios, plano de a√ß√£o e an√°lise de problemas")
    
    def load_data_from_database(self, database_path: str, contratante: str,
                                action_plan_path: str = None, problem_analysis_path: str = None) -> None:
        """
        Carrega os dados do CSV de banco de dados para o acompanhamento, filtrando pelo contratante.
        """
        import csv
        self.metrics_history = {}
        self.baseline_metrics = None
        self.current_metrics = None
        with open(database_path, newline='') as csvfile:
            reader = csv.DictReader(csvfile)
            rows = [row for row in reader if row['contratante'] == contratante]
            if not rows:
                raise ValueError(f"Nenhuma linha encontrada para contratante: {contratante}")
            for idx, row in enumerate(rows):
                metrics = {k: self._try_parse_number(v) for k, v in row.items() if k != 'contratante'}
                self.metrics_history[idx] = metrics
                if idx == 0:
                    self.baseline_metrics = metrics
                self.current_metrics = metrics
        self.cycle_count = len(rows)
        # Carrega plano de a√ß√£o e an√°lise de problemas (como no load_data)
        if action_plan_path:
            with open(action_plan_path, "r") as f:
                self.action_plan = f.read()
        else:
            self.action_plan = ""
        if problem_analysis_path:
            with open(problem_analysis_path, "r") as f:
                self.problem_analysis = f.read()
        else:
            self.problem_analysis = ""
        self.target_metrics = self._extract_targets_from_action_plan()

    @staticmethod
    def _try_parse_number(value):
        try:
            if value is None or value == '':
                return None
            if '.' in value or 'e' in value.lower():
                return float(value)
            return int(value)
        except Exception:
            return value
    
    def _extract_targets_from_action_plan(self) -> Dict[str, Any]:
        """
        Extrai as m√©tricas-alvo definidas no plano de a√ß√£o.
        
        Returns:
            Dicion√°rio com as m√©tricas-alvo extra√≠das
        """
        target_metrics = {}
        
        # Padr√£o para encontrar KPIs alvo no markdown
        kpi_pattern = r"(?:- \*\*KPIs Alvo\*\*:[\s\n]+((?:  - [^\n]+\n)+))"
        
        # Encontra todos os blocos de KPIs alvo
        kpi_blocks = re.findall(kpi_pattern, self.action_plan)
        
        # Para cada bloco, extrai os KPIs individuais
        for block in kpi_blocks:
            kpi_entries = re.findall(r"  - ([^:]+): ([^\n]+)", block)
            for kpi_name, kpi_value in kpi_entries:
                # Limpa e normaliza os valores
                kpi_name = kpi_name.strip()
                
                # Remove s√≠mbolos de porcentagem e cifr√£o para converter para n√∫mero
                value = kpi_value.strip()
                value = value.replace("%", "").replace("$", "").replace(",", "")
                
                try:
                    # Tenta converter para n√∫mero se poss√≠vel
                    if "." in value:
                        value = float(value)
                    else:
                        value = int(value)
                except ValueError:
                    # Mant√©m como string se n√£o for poss√≠vel converter
                    pass
                
                target_metrics[kpi_name] = value
        
        logging.info(f"Extra√≠das {len(target_metrics)} m√©tricas-alvo do plano de a√ß√£o")
        return target_metrics
    
    def analyze_metrics(self) -> Dict[str, Any]:
        """
        Analisa a evolu√ß√£o das m√©tricas ao longo do tempo.
        
        Returns:
            An√°lise de m√©tricas em formato JSON
        """
        logging.info("Analisando evolu√ß√£o das m√©tricas...")
        
        # Prepara inputs para o chain
        inputs = {
            "baseline_metrics": json.dumps(self.baseline_metrics, indent=2),
            "current_metrics": json.dumps(self.current_metrics, indent=2),
            "metrics_history": json.dumps(self.metrics_history, indent=2),
            "target_metrics": json.dumps(self.target_metrics, indent=2)
        }
        
        # Executa a an√°lise
        analysis_result = self.metrics_analysis_chain.run(**inputs)
        
        # Limpa e converte o resultado para JSON
        cleaned_result = self._clean_json_string(analysis_result)
        try:
            metrics_analysis = json.loads(cleaned_result)
            logging.info("An√°lise de m√©tricas conclu√≠da com sucesso")
            return metrics_analysis
        except json.JSONDecodeError as e:
            logging.error(f"Erro ao decodificar a an√°lise de m√©tricas: {e}")
            logging.error(f"Resultado limpo: {cleaned_result}")
            raise ValueError(f"Falha ao analisar m√©tricas: {e}")
    
    def track_actions(self, metrics_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Acompanha o status das a√ß√µes do plano original.
        
        Args:
            metrics_analysis: An√°lise de m√©tricas gerada pelo m√©todo analyze_metrics
            
        Returns:
            Status das a√ß√µes em formato JSON
        """
        logging.info("Acompanhando status das a√ß√µes...")
        
        # Prepara inputs para o chain
        inputs = {
            "action_plan": self.action_plan,
            "problem_analysis": self.problem_analysis,
            "metrics_evolution": json.dumps(metrics_analysis, indent=2)
        }
        
        # Executa o acompanhamento
        action_result = self.action_tracking_chain.run(**inputs)
        
        # Limpa e converte o resultado para JSON
        cleaned_result = self._clean_json_string(action_result)
        try:
            action_status = json.loads(cleaned_result)
            logging.info("Acompanhamento de a√ß√µes conclu√≠do com sucesso")
            return action_status
        except json.JSONDecodeError as e:
            logging.error(f"Erro ao decodificar o status das a√ß√µes: {e}")
            logging.error(f"Resultado limpo: {cleaned_result}")
            raise ValueError(f"Falha ao acompanhar a√ß√µes: {e}")
    
    def generate_report(self, 
                        metrics_analysis: Dict[str, Any], 
                        action_status: Dict[str, Any], 
                        cycle_number: int,
                        output_path: str) -> str:
        """
        Gera o relat√≥rio quinzenal de acompanhamento.
        
        Args:
            metrics_analysis: An√°lise de m√©tricas
            action_status: Status das a√ß√µes
            cycle_number: N√∫mero do ciclo de acompanhamento (1, 2, 3, etc.)
            output_path: Caminho para salvar o relat√≥rio gerado
            
        Returns:
            Relat√≥rio em formato markdown
        """
        logging.info(f"Gerando relat√≥rio para o ciclo {cycle_number}...")
        
        # Prepara a data do relat√≥rio (atual)
        report_date = datetime.now().strftime("%d/%m/%Y")
        
        # Prepara inputs para o chain
        inputs = {
            "metrics_analysis": json.dumps(metrics_analysis, indent=2),
            "action_status": json.dumps(action_status, indent=2),
            "cycle_number": str(cycle_number),
            "report_date": report_date
        }
        
        # Gera o relat√≥rio
        report = self.report_generation_chain.run(**inputs)
        
        # Salva o relat√≥rio
        with open(output_path, "w") as f:
            f.write(report)
        
        logging.info(f"Relat√≥rio gerado e salvo em: {output_path}")
        return report
    
    def generate_metrics_dashboard(self, 
                                   metrics_analysis: Dict[str, Any], 
                                   output_path: str) -> None:
        """
        Gera um dashboard visual das m√©tricas principais.
        
        Args:
            metrics_analysis: An√°lise de m√©tricas
            output_path: Caminho para salvar o dashboard
        """
        logging.info("Gerando dashboard de m√©tricas...")
        
        try:
            # Extrai os dados de m√©tricas da an√°lise
            metrics_data = metrics_analysis.get("metrics_comparison", [])
            
            if not metrics_data:
                logging.warning("Nenhum dado de m√©trica encontrado para gerar o dashboard")
                return
            
            # Limita a no m√°ximo 6 m√©tricas para o dashboard
            metrics_data = metrics_data[:6]
            
            # Cria uma figura com 2 gr√°ficos
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))
            
            # Gr√°fico 1: Valores atuais vs metas
            metric_names = [m["metric_name"] for m in metrics_data]
            current_values = [m["current_value"] for m in metrics_data]
            target_values = [m["target_value"] for m in metrics_data]
            
            x = range(len(metric_names))
            width = 0.35
            
            ax1.bar([i - width/2 for i in x], current_values, width, label='Valor Atual')
            ax1.bar([i + width/2 for i in x], target_values, width, label='Meta')
            
            ax1.set_title('Valores Atuais vs Metas')
            ax1.set_xticks(x)
            ax1.set_xticklabels(metric_names, rotation=45, ha='right')
            ax1.legend()
            
            # Gr√°fico 2: Taxa de progresso
            progress_rates = [float(m["progress_rate"].replace("%", "")) for m in metrics_data]
            
            # Cores baseadas no progresso
            colors = ['#ff9999' if rate < 30 else '#ffcc99' if rate < 70 else '#99cc99' for rate in progress_rates]
            
            ax2.barh(metric_names, progress_rates, color=colors)
            ax2.set_title('Taxa de Progresso (%)')
            ax2.set_xlim(0, 100)
            ax2.axvline(x=50, color='gray', linestyle='--')
            
            # Adiciona r√≥tulos de porcentagem
            for i, v in enumerate(progress_rates):
                ax2.text(v + 3, i, f"{v}%", va='center')
            
            plt.tight_layout()
            plt.savefig(output_path)
            
            logging.info(f"Dashboard de m√©tricas gerado e salvo em: {output_path}")
            
        except Exception as e:
            logging.error(f"Erro ao gerar dashboard de m√©tricas: {e}")
    
    def generate_action_status_dashboard(self, 
                                         action_status: Dict[str, Any], 
                                         output_path: str) -> None:
        """
        Gera um dashboard visual do status das a√ß√µes.
        
        Args:
            action_status: Status das a√ß√µes
            output_path: Caminho para salvar o dashboard
        """
        logging.info("Gerando dashboard de status das a√ß√µes...")
        
        try:
            # Extrai os dados de status do plano
            overall_status = action_status.get("overall_plan_status", {})
            
            if not overall_status:
                logging.warning("Nenhum dado de status encontrado para gerar o dashboard")
                return
            
            # Extrai os n√∫meros
            complete = overall_status.get("actions_complete", 0)
            in_progress = overall_status.get("actions_in_progress", 0)
            delayed = overall_status.get("actions_delayed", 0)
            not_started = overall_status.get("actions_not_started", 0)
            
            # Cria a figura
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))
            
            # Gr√°fico 1: Pizza de status das a√ß√µes
            labels = ['Completas', 'Em Andamento', 'Atrasadas', 'N√£o Iniciadas']
            sizes = [complete, in_progress, delayed, not_started]
            colors = ['#99cc99', '#ffcc99', '#ff9999', '#dddddd']
            
            ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', 
                    startangle=90, wedgeprops={'edgecolor': 'white'})
            ax1.axis('equal')
            ax1.set_title('Status das A√ß√µes')
            
            # Gr√°fico 2: Taxa de conclus√£o do plano
            overall_completion = float(overall_status.get("overall_completion", "0").replace("%", ""))
            
            # Cria um gr√°fico de progresso
            ax2.barh(['Progresso Total'], [overall_completion], color='#aaddff')
            ax2.barh(['Progresso Total'], [100], color='#eeeeee')
            ax2.set_title('Conclus√£o Geral do Plano')
            ax2.set_xlim(0, 100)
            
            # Adiciona r√≥tulo de porcentagem
            ax2.text(overall_completion + 3, 0, f"{overall_completion}%", va='center')
            
            plt.tight_layout()
            plt.savefig(output_path)
            
            logging.info(f"Dashboard de status das a√ß√µes gerado e salvo em: {output_path}")
            
        except Exception as e:
            logging.error(f"Erro ao gerar dashboard de status das a√ß√µes: {e}")
    
    def _clean_json_string(self, json_string: str) -> str:
        """
        Limpa uma string JSON de poss√≠veis elementos de formata√ß√£o.
        
        Args:
            json_string: String JSON a ser limpa
            
        Returns:
            String JSON limpa
        """
        # Remove blocos de c√≥digo markdown
        json_string = re.sub(r'```json\s*', '', json_string)
        json_string = re.sub(r'```\s*', '', json_string)
        
        # Limpa espa√ßos extras no in√≠cio e fim
        json_string = json_string.strip()
        
        return json_string
    
    def run_analysis_cycle(self, 
                        scenario_pattern: str, 
                        action_plan_path: str, 
                        problem_analysis_path: str,
                        cycle_number: int,
                        output_dir: str = "./output") -> Dict[str, str]:
        """
        Executa um ciclo completo de an√°lise e gera todos os relat√≥rios.
        """
        os.makedirs(output_dir, exist_ok=True)
        report_path = os.path.join(output_dir, f"relatorio_quinzenal_ciclo_{cycle_number}.md")
        metrics_dashboard_path = os.path.join(output_dir, f"dashboard_metricas_ciclo_{cycle_number}.png")
        actions_dashboard_path = os.path.join(output_dir, f"dashboard_acoes_ciclo_{cycle_number}.png")

        # S√≥ carrega dados se scenario_pattern n√£o for None (modo antigo)
        if scenario_pattern is not None:
            self.load_data(scenario_pattern, action_plan_path, problem_analysis_path)

        metrics_analysis = self.analyze_metrics()
        action_status = self.track_actions(metrics_analysis)
        report = self.generate_report(metrics_analysis, action_status, cycle_number, report_path)
        self.generate_metrics_dashboard(metrics_analysis, metrics_dashboard_path)
        self.generate_action_status_dashboard(action_status, actions_dashboard_path)

        return {
            "report": report_path,
            "metrics_dashboard": metrics_dashboard_path,
            "actions_dashboard": actions_dashboard_path
        }

def main():
    """Fun√ß√£o principal para executar o agente de acompanhamento quinzenal."""
    print("=== AGENTE DE ACOMPANHAMENTO QUINZENAL DE ESTOQUE ===")
    print("Este agente analisa a evolu√ß√£o das m√©tricas de estoque e acompanha o progresso das a√ß√µes implementadas.")

    # Novo fluxo para usar database.csv
    database_path = str(input("Digite o caminho para o arquivo database.csv (ex: './cenarios/database.csv'): ")) or "./cenarios/database.csv"
    contratante = str(input("Digite o nome do contratante (ex: 'a_0'): "))
    action_plan_path = str(input("Digite o caminho para o arquivo do plano de a√ß√£o (ex: './plans/action_plan_pt_cenario_a.md'): ")) or "./plans/action_plan_pt_cenario_a.md"
    problem_analysis_path = str(input("Digite o caminho para o arquivo de an√°lise de problemas (ex: './plans/problem_analysis_pt_cenario_a.md'): ")) or "./plans/problem_analysis_pt_cenario_a.md"
    output_dir = input("Digite o diret√≥rio de sa√≠da para os relat√≥rios (ex: './output'): ") or "./output"

    try:
        agent = InventoryTrackingAgent(model_name="gpt-4o", temp=0.2)
        agent.load_data_from_database(database_path, contratante, action_plan_path, problem_analysis_path)
        cycle_number = getattr(agent, 'cycle_count', 1)
        # Executa o ciclo de an√°lise
        output_files = agent.run_analysis_cycle(
            scenario_pattern=None,  # N√£o usado neste fluxo
            action_plan_path=action_plan_path,
            problem_analysis_path=problem_analysis_path,
            cycle_number=cycle_number,
            output_dir=output_dir
        )
        print("\n=== AN√ÅLISE CONCLU√çDA COM SUCESSO ===")
        print(f"Relat√≥rio quinzenal: {output_files['report']}")
        print(f"Dashboard de m√©tricas: {output_files['metrics_dashboard']}")
        print(f"Dashboard de status das a√ß√µes: {output_files['actions_dashboard']}")
    except Exception as e:
        print(f"\nERRO: {e}")
        logging.error(f"Erro na execu√ß√£o do agente: {e}", exc_info=True)
        return 1
    return 0

if __name__ == "__main__":
    sys.exit(main())